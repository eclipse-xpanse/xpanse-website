{"searchDocs":[{"title":"Introduction to Open Services Cloud","type":0,"sectionRef":"#","url":"/xpanse/blog/2022/07/14/introduction","content":"Welcome to Eclipse Open Services Cloud. Today, the ecosystem is being locked out of public clouds. Only the cloud providers can create native managed services. The consequence is that it's pretty hard to integrate 3rd party SaaS islands. On the other hand, the enterprises fear lock-in. There's no real service portability between different clouds. And even worse, cloud data is the ultimate lock-out and lock-in. The data lock-out means cloud data storage software is inefficient compare to cloud data storage service. Even if we can have a software storage on a purchased virtual machine, it's inefficient and expensive compared to native cloud storage services. The data lock-in is because the cloud data is tightly coupled to prorprietary cloud services. It's hard to extract/export raw data from one cloud to another. Even if cloud data can be exported, it's not really useful without the accompanying cloud service. Open Services Cloud solves: federated: the goal is to create an open services ecosystem that works across different clouds. Open Services Cloud solves ecosystem lockout &amp; lack of service portability.open: the purpose is to enable customers to choose the services and providers of their choice. Thanks to that, we avoid customer lock-in.data infrastructure based on European values: Open Services Cloud enables European cloud providers and ecosystems to meet the needs of Europeans. Open Services Cloud open up the market, avoiding the hyperscalers to control and set the market for cloud and data services in Europe. Open Services Cloud is a Open Source initiative reshaping the cloud market. Welcome to Open Services Cloud!","keywords":"","version":null},{"title":"Open Services Cloud and GAIA-X, digital sovereignty","type":0,"sectionRef":"#","url":"/xpanse/blog/2022/07/20/gaiax","content":"As GAIA-X shapes data sovereignty, and Open Services Cloud frames technology sovereignty, both combined provides digital sovereignty. In details, it means: GAIA-X focuses on portability of cloud dataOpen Services Cloud focuses on portability of cloud data processing services and also fulfills the Data Act's requirements for cloud services portabilityYou need to have both portability of data and its associated data processing service to achieve digital sovereignty. One without the other has limited value.We implement GAIA-X data portability as services on top of Open Services Cloud to bring together these two features, **data portability and data processing portability££.","keywords":"","version":null},{"title":"Architecture","type":0,"sectionRef":"#","url":"/xpanse/docs/architecture","content":"Architecture Xpanse is a project aimed reshaping the cloud services ecosystem: the cloud users can find the same services across different cloud providers, exactly the same services provided by Xpanse.the software vendors can easily create native and portable managed services for their software, including seamless and low level integration with cloud provider services. In addition, of software artifacts, software vendor describe the service using the Xpanse data model.the cloud providers can easily extend their services catalog by registering services described using the Xpanse data model. Xpanse allows anyone to create managed services (not only the cloud provider), portable, and fully integrated within the cloud provider infrastructure. The Xpanse service descriptor is a yaml fully describing the service. This descriptor is handled by the orchestrator. The orchestrator reads the deployment scripts provided as part of the service descriptor and executes it when the service is ordered. The interaction logic with the cloud provider is delegated to orchestrator plugins. The orchestrator can use one or more plugins to deal with the underlying infrastructure services and create the service resources. The orchestrator defines the following lifecycle for each service: A service is registered in the orchestrator (in a persistent store).Once registered, the service is available for the end user for deployments.the orchestrator can delete the service and with this will remove the service from the catalog. You can interact with the Xpanse API using the REST API.The orchestrator, plugins and API are all managed in the Xpanse runtime Spring Boot application. The runtime is the glue between all components.","keywords":"","version":"Next"},{"title":"Configuration Language","type":0,"sectionRef":"#","url":"/xpanse/docs/configuration-language","content":"","keywords":"","version":"Next"},{"title":"Deployment Scripts​","type":1,"pageTitle":"Configuration Language","url":"/xpanse/docs/configuration-language#deployment-scripts","content":" In XSDL, the deployer can contain the script that must be executed for provisioning the managed service. Currently, the only allowed script is Terraform.  ","version":"Next","tagName":"h3"},{"title":"Flavors​","type":1,"pageTitle":"Configuration Language","url":"/xpanse/docs/configuration-language#flavors","content":" For each managed service, we can define different flavors of it. For example, different sizes of the VM, etc. End user can then select the flavor of their preference for the service while ordering.  ","version":"Next","tagName":"h3"},{"title":"Flavor properties​","type":1,"pageTitle":"Configuration Language","url":"/xpanse/docs/configuration-language#flavor-properties","content":" Flavors can have properties which can be simply declared and referred in the deployment script too with the same property names. Runtime will ensure that these variables are automatically available for the deployment scripts  ","version":"Next","tagName":"h3"},{"title":"Deployment Variables​","type":1,"pageTitle":"Configuration Language","url":"/xpanse/docs/configuration-language#deployment-variables","content":" As part of the XSDL, the managed service provider can define variables that can be either entered by the user or available as defaults or variables that can be read for any other sources such as the environment variables. All possible types of variables are defined here Deployment VariablesThe variables can then be used in the deployment scripts.  ","version":"Next","tagName":"h3"},{"title":"XSDL loading​","type":1,"pageTitle":"Configuration Language","url":"/xpanse/docs/configuration-language#xsdl-loading","content":" Xpanse provides different options to register service templates defined using XSDL:  REST API on the xpanse runtimeXpanse UI ","version":"Next","tagName":"h2"},{"title":"Cloud Provider Credentials","type":0,"sectionRef":"#","url":"/xpanse/docs/cloud-provider-credentials","content":"","keywords":"","version":"Next"},{"title":"Authentication Capabilities​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#authentication-capabilities","content":" Each cloud provider allows different ways for its clients to authenticate itself and consume its API. For example, the same CSP might support username/password, API key, Oauth2 etc., as possible ways to connect to its API.  While Xpanse plugins are responsible for integrating with the cloud provider APIs, it might not have implemented all possible ways to authenticate itself to the cloud provider API.  Every Xpanse Plugin will define the authentication methods it supports to connect to its underlying cloud provider. This configuration is added and exposed by implementing the AuthenticationCapabilitiesinterface by the corresponding plugin.  The same information is also made available to consumers via the REST API method getCredentialCapabilitiesByCspin the CredentialsApi, which returns all credential types defined and supported by the plugin.  This list is enhanced as and when Xpanse plugin for a specific CSP adds integration for new authentication methods supported by the CSP APIs.  ","version":"Next","tagName":"h2"},{"title":"Credential Configuration​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#credential-configuration","content":" Each credential configuration defined by a plugin contains the following information  Credential Type: variables, username/password, API key, Oauth2 etc.Dependent configuration: In case of Variables, the variable names and its values that must be provided so that the plugin can connect to the respective cloud provider.  ","version":"Next","tagName":"h3"},{"title":"Credential Type - Variables​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#credential-type---variables","content":" This is the only type that is currently implemented in Xpanse. This will be extended in the near future.  Credential Variable Value Sources​  After a plugin has defined credential Type as variables and its respective variable names, then the consumer of this cloud provider, then values for these variable names must be provided, and this is possible to be done from different variable sources.  This is necessary to allow all combinations where some credential variable values are fixed for an environment and some can be different for each user. For example, in the case of Openstack plugin, the Identity URL might be fixed for each Xpanse instance, but the username and password can vary for each Xpanse user.  Xpanse User Specific Credentials​  A credential for combination of a specific CSP, CredentialType and a specific Xpanse user can be added using the addCredential API method. This means for all services ordered by a Xpanse user or for monitoring services which are ordered by this specific Xpanse user, this added credential will be used.  This exact request body definition for each of the CSP and Credential Types can be found using getCredentialOpenApi. This method provides a link to OpenAPI definition and sample request for adding credentials for each CSP.  Credential variable values sent from this API are stored directly into CredentialCache.  OS Environment Variables​  Based on the CredentialDefinition configured in the Plugins, the Xpanse runtime can be started by injecting default credential configuration variables as OS environment variables to the runtime. If values for all credential variables are not available from other sources, then the runtime will search for credential variables from OS environment variables.  Please note that the variables from OS environment values are read as-is. It is therefore necessary to keep credential variable names unique even between two different credential types of the same CSP.  Credential Variables &quot;Joining&quot;​  As described in the above sections, for each credential type, a certain set of variables are defined. Values for allof these variables are needed for the credential to be valid.  We join credential variable values from all the sources mentioned in the above sectionsto get the final credential variable values that will be used for connecting to the CSP.  Credential values are read from different values and joined into one single set of all required credential variable values of a given type.  If the value of a credential variable is available in multiple sources, then the value coming from the source of higher priority is used.  Service Deployment​  During the service deployment, all the values for the variables defined in the CredentialDefinition is derived from different sources in a priority sequence provided below  CredentialType and variables from deploy variables. As part of the registering services, the service provider can define what type of credentials is needed for ordering the service. The end user must add this credential using addCredential method. This will add credentials to CredentialsCache. Credential variable values from OS environment variables.    Service Monitoring​  During the service monitoring, all the values for the variables defined in the CredentialDefinition is derived from different sources in a priority sequence provided below  Credentials available in the CredentialsCache.credential variables from OS environment variables.    ","version":"Next","tagName":"h3"},{"title":"Credential Cache​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#credential-cache","content":" Credential cache is the credential store in Xpanse runtime which stores all credential data which are required to be used in the later phase of the workflows. Credentials provided by the API are stored as an in-memory cache map.  ","version":"Next","tagName":"h2"},{"title":"Cache Eviction​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#cache-eviction","content":" Credentials are evicted from cache after the provided expiry time or by default after 1 hour.  ","version":"Next","tagName":"h3"},{"title":"Data Encryption​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#data-encryption","content":" When the runtime is started with an AES secure key, then all sensitive data is encrypted and stored in the JVM. More information can be found here.  ","version":"Next","tagName":"h3"},{"title":"Multiple Credentials Found​","type":1,"pageTitle":"Cloud Provider Credentials","url":"/xpanse/docs/cloud-provider-credentials#multiple-credentials-found","content":" When multiple credentials are found in the credential cache for the same Xpanse user, credential type, and CSP, then we simply use the first available credential. ","version":"Next","tagName":"h3"},{"title":"Bug Handling Process","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/bug-handling-process","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#overview","content":" Xpanse is aiming to build a secure system from the foundation, applying the best industry practices in terms of development quality. However, as in every software projects, bugs do happen. This process explains how we handle bugs.  ","version":"Next","tagName":"h2"},{"title":"How to Report a Bug?​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#how-to-report-a-bug","content":" If you think you have found a bug in Xpanse, please open an issue in GitHub and in the project that you think is the source of the issue. Use the provided template:  What is the action to reproduce the bug? (Steps to reproduce)What is the result you see? (Actual result)What is the result you expect? (Expected behaviour)Frequency? (always, sometimes, one-time issue)Tested version (Release or commit version, platform)Do you know any workaround of this issue? (link to workaround/mitigation steps etc)Do you have a fix for this issue?  Developers review the reported issues and perform triage (see below). When a fix is available, the ticket is updated with the details of the solution.  ","version":"Next","tagName":"h2"},{"title":"Bug Triage​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#bug-triage","content":" The bug triage is a process where developers asses the bug and set its severity and domain. At the end of this process the bug will:  Be classified as a security issue, normal bug, feature request, or be rejected if the feature is working as planned or could not be reproduced.Have its severity set. Please refer to the documentation of severity levels below.  If the bug is classified as a security vulnerability, please also refer to our security guidelines here.  If the bug is confirmed as a bug, the developer will assign bug severity: critical, major, minor or low.  Note: Critical severity bugs make a feature unusable, cause a major data loss. There is no workaround, or a complex one. Normal severity bugs make a feature hard to use, but there is a workaround (including another feature to use instead of the desired one). Minor severity bugs cause a loss of non-critical feature (like missing or incorrect logging). Low severity bugs cause minor inconveniences (like a typo in the user interface or in the documentation).  The bug can originate in the software developed by the project, or from the dependencies we use from other sources. The process of handling a bug report will change between those two cases:  ","version":"Next","tagName":"h2"},{"title":"When the Issue is in the Code Developed by the Project`​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#when-the-issue-is-in-the-code-developed-by-the-project","content":" In the case where the bug originates in the code directly maintained by the Project, the bug is handled directly in the bug tracker.  ","version":"Next","tagName":"h3"},{"title":"When the Issue Originates from Dependencies​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#when-the-issue-originates-from-dependencies","content":" If the issue was identified in dependencies code, we report an issue in a way appropriate to that particular dependency project. We store the reference to their bug report in our bug tracker. Depending on the bug severity, we might decide to develop and maintain a fix locally. However, we strongly prefer the dependency library maintainers to fix the issue first, and then get it with a regular dependency version update.  Please note also that we periodically update maintained dependencies, regardless of the bugs filled in our system. Our goal is to update to the latest stable version of the project.  ","version":"Next","tagName":"h3"},{"title":"Detailed Workflow​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#detailed-workflow","content":" ","version":"Next","tagName":"h2"},{"title":"Bug Sources​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#bug-sources","content":" Bugs might be reported by different sources, including Project's own findings (like QA), partner findings or community. There might be also different ways the Project team learns about the issue, including chats, discussion forums etc. Issues coming from different sources are centralized in the bug tracker, which also provides a unified identification of all issues.  ","version":"Next","tagName":"h3"},{"title":"Acknowledgement and Bug Triage​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#acknowledgement-and-bug-triage","content":" After the bug is entered, a developer will perform triage. The process starts from acknowledging the issue and then consists of verifying all the information provided by the bug reporter to reproduce the issue. The developer performing triage might ask additional questions. Then they assign severity and domain to the issue in the bug tracker. They also check which versions are affected and might modify the severity level set by the reporter. Any project member, or the bug reporter, who disagrees with the assignment might comment on the issue.  If there is a fix available from the reporter, the developer also verifies if the fix is correct and matches the IP policy. If the fix is judged acceptable, the process might skip to the Releasing step.  We aim at the first answer of the triage (either finishing triage, or additional questions to the reporter) in three working days for critical bugs and seven days for other bugs. In case of a critical bug, the person performing triage informs the maintainers of the affected subsystem.  ","version":"Next","tagName":"h3"},{"title":"Prioritizing and Fixing​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#prioritizing-and-fixing","content":" Bugs with the severity attached enter the prioritization process. It includes a weekly meeting when the team reviews bugs entered or modified during the last week: those during the process of triage, and those with the triage finished. For the bugs with triage finished, the team sets the priority and might assign it to a developer.  The bug fixes should follow the same contributions guidelines as any other contribution. The best practice is to develop a fix for the bug in a separate branch. Fixes for related bugs are possible in the same branch.  ","version":"Next","tagName":"h3"},{"title":"Releasing​","type":1,"pageTitle":"Bug Handling Process","url":"/xpanse/docs/Contribute/bug-handling-process#releasing","content":" When a bug fix is available in a branch, the developer creates a merge request. When the change is accepted, it is merged in the main branch. The developer in charge of the bug verifies with the release manager to which branches the change should be backported.  If the bug comes from a dependent library, developers upstream the bug fix. If the upstream is delayed, the Project might ship a local fix. However, we aim at upstreaming all fixes.  During the time of development of the patch and eventual upstream, the developer updates the documentation (if appropriate), and adds a notification to the release notes. Our release notes contain: links to bugs fixed in the release, links to CVEs fixed in the release (publicly known) and a list of CVEs fixed that are still under embargo.  If the bug is classified as critical, it might be decided to perform a separate bugfix release to fix the issue. Otherwise, the bug fix lands in the next bugfix release. ","version":"Next","tagName":"h3"},{"title":"Authentication and Authorization","type":0,"sectionRef":"#","url":"/xpanse/docs/authentication-authorization","content":"","keywords":"","version":"Next"},{"title":"OIDC​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#oidc","content":" Authentication and Authorization are implemented using OIDC (OpenID Connect). This helps us to outsource the security layer to an external Identity Provider and thereby not storing any user data within Xpanse.  ","version":"Next","tagName":"h2"},{"title":"OIDC Providers and its Configuration​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#oidc-providers-and-its-configuration","content":" Similar to other integrations provided in Xpanse, the runtime can be extended to be integrated with any Identity Provider that supports OIDC standards. It is not limited to any specific product.  Any OIDC provider cannot be used directly out of the box. It needs a variety of configurations on the provider. From Xpanse project, we aim to provide 'Infrastructure as Code' which will automate all required configuration on the Identity provider.  All Identity provider related configuration on consumers can only be obtained only after the OIDC provider is fully configured with the consumer detail  ","version":"Next","tagName":"h3"},{"title":"Zitadel​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#zitadel","content":" As a default implementation, Xpanse runtime is integrated with Zitadel Identity Provider.  To enable Zitadel authentication layer, the runtime must be started with zitadel profile.  More details can be found here..  ","version":"Next","tagName":"h2"},{"title":"Zitadel Installation​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#zitadel-installation","content":" Zitadel instance for local development can be setup using the steps mentioned here..  An example for setting up production like Zitadel instance can be found in our testbed installation steps here..  ","version":"Next","tagName":"h3"},{"title":"Zitadel Provider Configuration​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#zitadel-provider-configuration","content":" After starting the vanilla Zitadel application, all required configurations can be applied using the Terraform scripts provided. All steps required for initial configuration are available here.  ","version":"Next","tagName":"h3"},{"title":"Zitadel Consumer Configuration​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#zitadel-consumer-configuration","content":" All generated configuration details can be obtained as documented here.  Runtime​  Runtime application needs the following properties to be set for the authentication and authorization to work.  authorization.server.endpointauthorization.api.client.idauthorization.api.client.secretauthorization.swagger.ui.client.id  UI​  UI can be then started using the consumer details as documented here.  End Users Configuration​  At the moment, it is only feasible to create user only via the Zitadel UI as we do not have SMTP available which is needed for self-registration of users.  Admin Users​  By default, Zitadel provides a root user using which other users can be created and also made other administrators. Only these users can add other end-users on Zitadel.  ","version":"Next","tagName":"h3"},{"title":"Role Based Access Control - RBAC​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#role-based-access-control---rbac","content":" We use OIDC providers to also implement RBAC on Xpanse runtime API and also in UI.  ","version":"Next","tagName":"h2"},{"title":"Roles​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#roles","content":" To keep our initial role configuration simple, the following roles are considered  user - this is the role allocated to end user. isv - this is the role allocated to ISV (independent software vendor) users. admin - this is the role allocated to administrators running Xpanse. Default Role - When no roles are assigned to a user, then every registered is by default assumed to have the user role.  ","version":"Next","tagName":"h3"},{"title":"Role Assignment​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#role-assignment","content":" After the end users are registered/created on Zitadel, the administrator must assign roles to the user.  This option can be found on the UI under - users -&gt; click on user -&gt; Authorizations -&gt; + New  ","version":"Next","tagName":"h3"},{"title":"Role Validation​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#role-validation","content":" Each API method is configured to be allowed only for specific roles. Spring Security fetches the user information from Identity Provider and based on the roles allocated to the user, we decide if the user is allowed to access an API or not. If the user is not authorized to access, then API returns HTTP code 403.Xpanse UI fetches the user information from Identity Provider and based on the roles allocated to the user, menu options are displayed in the UI.  ","version":"Next","tagName":"h3"},{"title":"Attribute Based Access Control - ABAC​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#attribute-based-access-control---abac","content":" ","version":"Next","tagName":"h2"},{"title":"OIDC Metadata​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#oidc-metadata","content":" In order to allow service vendors to manage only their own services, we use ABAC. This is achieved by using OIDC's metadata feature to assign isv users to a specific namespace.    While registering a service, the service vendor must specify the same namespace value in the namespace field. With this, users of another namespace will not be allowed to view, update or delete these service templates.  ","version":"Next","tagName":"h3"},{"title":"Execute authenticated APIs​","type":1,"pageTitle":"Authentication and Authorization","url":"/xpanse/docs/authentication-authorization#execute-authenticated-apis","content":" When the application has activated authorization with 'zitadel' profile, all protected APIs must have anAuthorization header in the Bearer ${access token} format in the http request. Here are two ways to get access_token for executing authenticated APIs:  The first way is to open the Swagger-UI page of the Xpanse server. In case of local development server, the Swagger-UI is reachable on http://localhost:8080/swagger-ui/index.html.  Click on the 'Authorize' button on the SwaggerUI page to open the authentication window. Click on the 'select all' option to select all 'Scopes' and click on 'Authorize'  The browser will redirect to the login page of the IAM service. Fill username and password to complete user login. Once the login is successful, the control is automatically redirected to the Swagger-UI page. Close the authentication window and select the API which you want to execute and click to expand it, then click on 'Try it out' and 'Execute' to execute the API method. In the Curl command, you can see the request header named Authorization with the value of${access_token} after prefix Bearer .  The other way is to use the Authorize REST API. Call the method using browser. In case of local development server, the URL is http://localhost:8080/auth/authorize. The browser will redirect to the login page of the IAM service. Fill username and password to complete user login. After successful login in the IAM, the browser will back to the token API url with response model 'TokenResponse' with field 'access_token.' Then you can use the value of 'access_token' to fill header 'Authorization' in the http request when executing authenticated APIs with CLI or the other http client tools. ","version":"Next","tagName":"h2"},{"title":"Calendar","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/calendar","content":"Calendar Our meetings are publicly announced on our Google calendar and the community is welcome to join them. You can navigate either through the calendar below or subscribe from your email client using our ICS File.","keywords":"","version":"Next"},{"title":"Code of conduct","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/code-of-conduct","content":"","keywords":"","version":"Next"},{"title":"Our pledge​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#our-pledge","content":" In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our collective and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.  ","version":"Next","tagName":"h2"},{"title":"Our standards​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#our-standards","content":" Examples of behavior that contributes to creating a positive environment include:  Using welcoming and inclusive languageBeing respectful of differing viewpoints and experiencesGracefully accepting constructive criticismFocusing on what is best for the communityShowing empathy towards other community members  Examples of unacceptable behavior by participants include:  The use of sexualized language or imagery and unwelcome sexual attention or advancesTrolling, insulting/derogatory comments, and personal or political attacksPublic or private harassmentPublishing others’ private information, such as a physical or electronic address, without explicit permissionOther conduct which could reasonably be considered inappropriate in a professional setting  ","version":"Next","tagName":"h2"},{"title":"Our responsibilities​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#our-responsibilities","content":" Maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.  Maintainers have the right and responsibility to edit, delete, hide, or lock code, comments, commits, edits, issues, posts, pull requests, and other contributions that are not aligned to this code of conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.  ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#scope","content":" This code of conduct applies both within collective spaces and in public spaces when an individual is representing the collective or its community.  Examples of representing a collective or community include using an official collective email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.  Representation of the collective may be further defined and clarified by maintainers.  ","version":"Next","tagName":"h2"},{"title":"Enforcement​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#enforcement","content":" Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team.  All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.  Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project’s leadership.  ","version":"Next","tagName":"h2"},{"title":"Attribution​","type":1,"pageTitle":"Code of conduct","url":"/xpanse/docs/Contribute/code-of-conduct#attribution","content":" This code of conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html  For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq ","version":"Next","tagName":"h2"},{"title":"Continuous Integration","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/continuous-integration","content":"","keywords":"","version":"Next"},{"title":"Xpanse Repository​","type":1,"pageTitle":"Continuous Integration","url":"/xpanse/docs/Contribute/continuous-integration#xpanse-repository","content":" The Xpanse Repository contains the main backend application for Xpanse project and is written in Java.  CI pipeline for this repository is defined here as GitHub actions. This Job builds complete project, runs all tests and also checks for the code format.  ","version":"Next","tagName":"h3"},{"title":"Xpanse UI Repository​","type":1,"pageTitle":"Continuous Integration","url":"/xpanse/docs/Contribute/continuous-integration#xpanse-ui-repository","content":" The Xpanse UI Repository contains the frontend application for Xpanse project and is written in TypeScript and based on ReactJS library.  CI pipeline for this repository is defined here as GitHub actions. This Job runs the ES linter and prettier formatter checks.  ","version":"Next","tagName":"h3"},{"title":"Xpanse Website Repository​","type":1,"pageTitle":"Continuous Integration","url":"/xpanse/docs/Contribute/continuous-integration#xpanse-website-repository","content":" The Xpanse Website Repository contains the documentation for Xpanse project and is written in TypeScript and based on Docusaurus library.  CI pipeline for this repository is defined here as GitHub actions. This Job runs the ES linter and prettier formatter checks.  ","version":"Next","tagName":"h3"},{"title":"Pull Requests and CI Pipelines​","type":1,"pageTitle":"Continuous Integration","url":"/xpanse/docs/Contribute/continuous-integration#pull-requests-and-ci-pipelines","content":" All PRs on the respective repositories can be merged only when the underlying CI pipeline is successful. ","version":"Next","tagName":"h2"},{"title":"New Developers","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/new-developers","content":"","keywords":"","version":"Next"},{"title":"Creating an account on Eclipse Foundation​","type":1,"pageTitle":"New Developers","url":"/xpanse/docs/Contribute/new-developers#creating-an-account-on-eclipse-foundation","content":" Head to the Eclipse foundation websiteand set up an account by entering your:  EmailUsernameFull nameOrganizationPasswordCountry  Then read and check the box to agree to Terms of Use, Privacy Policy and Code of Conduct. When you complete that, follow the instructions sent to your email to activate the account.  ","version":"Next","tagName":"h2"},{"title":"Signing the ECA​","type":1,"pageTitle":"New Developers","url":"/xpanse/docs/Contribute/new-developers#signing-the-eca","content":" In order to contribute to the eclipse-xpanse, you need to sign the  Eclipse Contributor Agreement  which describes the terms under which you can contribute to the project.  If you sign this ECA, you confirm your legal rights to submit the code to the project. You also provide license to your contributions to Eclipse and specified users, however you still own your contributions.  ","version":"Next","tagName":"h2"},{"title":"GitHub user​","type":1,"pageTitle":"New Developers","url":"/xpanse/docs/Contribute/new-developers#github-user","content":" Since Xpanse uses GitHub as its code repository, Developer's GitHub user ID must be configured in Eclipse Foundation Account. Without this any contributions cannot be merged. . Steps are documented here.  ","version":"Next","tagName":"h2"},{"title":"Eclipse Foundation Contributor​","type":1,"pageTitle":"New Developers","url":"/xpanse/docs/Contribute/new-developers#eclipse-foundation-contributor","content":" Contributor guidelines from Eclipse foundation can be additionally found here. ","version":"Next","tagName":"h2"},{"title":"Planning","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/planning","content":"","keywords":"","version":"Next"},{"title":"Agile Development Process​","type":1,"pageTitle":"Planning","url":"/xpanse/docs/Contribute/planning#agile-development-process","content":" We follow Agile/Scrum development process. Each sprint is 2 weeks long.  ","version":"Next","tagName":"h3"},{"title":"Sprint Planning​","type":1,"pageTitle":"Planning","url":"/xpanse/docs/Contribute/planning#sprint-planning","content":" Sprint Planning meeting happens every alternate Mondays.GitHub Milestones is used for scheduling, planning and reporting sprint deliveries.All topics planned in sprints are only tracked as GitHub issues  ","version":"Next","tagName":"h3"},{"title":"Roadmap & Backlog​","type":1,"pageTitle":"Planning","url":"/xpanse/docs/Contribute/planning#roadmap--backlog","content":" At the moment, all open topics are documented in the GitHub Project. ","version":"Next","tagName":"h3"},{"title":"Security Policy","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/security","content":"","keywords":"","version":"Next"},{"title":"Versions​","type":1,"pageTitle":"Security Policy","url":"/xpanse/docs/Contribute/security#versions","content":" The latest version of Xpanse is supported.  ","version":"Next","tagName":"h2"},{"title":"Reporting a Vulnerability​","type":1,"pageTitle":"Security Policy","url":"/xpanse/docs/Contribute/security#reporting-a-vulnerability","content":" If you think you found a vulnerability, and even if you are not sure about it, please report it right away by sending an email to: xpanse-dev. Please try to be as explicit as possible, describing all the steps and example code to reproduce the security issue.  We will review it thoroughly and get back to you as fast as possible.  ","version":"Next","tagName":"h2"},{"title":"Public Discussions​","type":1,"pageTitle":"Security Policy","url":"/xpanse/docs/Contribute/security#public-discussions","content":" Please restrain from publicly discussing a potential security vulnerability.  It's better to discuss privately and try to find a solution first, to limit the potential impact as much as possible.  ","version":"Next","tagName":"h2"},{"title":"Eclipse Foundation Guidelines​","type":1,"pageTitle":"Security Policy","url":"/xpanse/docs/Contribute/security#eclipse-foundation-guidelines","content":" Eclipse Foundation guidelines for reporting vulnerabilities can be found here. ","version":"Next","tagName":"h2"},{"title":"Pull Requests","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/pull-requests","content":"Pull Requests All changes to source code is possible only via Pull Requests on GitHub. Every pull request should be &quot;linked&quot; to an issue.Create a branch using: $ git clone https://github.com/eclipse-xpanse/xpanse git fetch --all git checkout -b my-branch origin/main Don't forget to periodically rebase your branch git rebase -i origin/mainIf you have a group of commits related to the same change, please squash your commits into one and force push to your branch.Test that your change works by adapting or adding tests.Follow the boy scout rule to &quot;Always leave the campground cleaner than you found it.&quot;Build your changes, In case of Xpanse App, make sure you do a build before doing a PR. and the build has to be successful $ mvn clean verify In case of Xpanse UI and website, make sure the application starts without any errors and warnings: $ npm run start If your PR has conflicts with the main then rebase the branch. PRs with conflicts are unlikely to be appliedDo not change too much in a PR. The smaller the PR the easier it is to review, apply and the faster it will be doneEven if we are monitoring closely the PR, if you think your PR doesn't move forward fast enough, do not hesitate to ping in a PR comment to get some update.","keywords":"","version":"Next"},{"title":"Releases","type":0,"sectionRef":"#","url":"/xpanse/docs/Contribute/releases","content":"","keywords":"","version":"Next"},{"title":"Xpanse Website​","type":1,"pageTitle":"Releases","url":"/xpanse/docs/Contribute/releases#xpanse-website","content":" We re-deploy the Xpanse website for every commit that is done to the main branch.  Continuous deployment is implemented based on GitHub actions as configured here.  ","version":"Next","tagName":"h2"},{"title":"Xpanse Stack​","type":1,"pageTitle":"Releases","url":"/xpanse/docs/Contribute/releases#xpanse-stack","content":" All application necessary to run the Xpanse stack are released as docker images in the GitHub docker registry. Java applications are additionally released as jar files which can be downloaded directly from the GitHub release notes.  Docker images can be found at GitHub Packages. ","version":"Next","tagName":"h2"},{"title":"Database","type":0,"sectionRef":"#","url":"/xpanse/docs/database","content":"","keywords":"","version":"Next"},{"title":"Development Environments​","type":1,"pageTitle":"Database","url":"/xpanse/docs/database#development-environments","content":" For all development purposes, we use a file-based H2 database which is automatically created during the server startup.  ","version":"Next","tagName":"h2"},{"title":"Admin UI​","type":1,"pageTitle":"Database","url":"/xpanse/docs/database#admin-ui","content":" The UI to the H2 DB can be accessed at http://localhost:8080/h2-console/login.jsp. Credentials to this admin UI can be found here.  ","version":"Next","tagName":"h3"},{"title":"Cleanup​","type":1,"pageTitle":"Database","url":"/xpanse/docs/database#cleanup","content":" Since it is a file-based database, the entries are not lost with reboot of the server.  To clean up the database, the database files must be simply deleted and the server must be restarted for new fresh DB files to be recreated. Execute the below command on the root of the folder xpanse project.  rm *.db   Note: The H2 database is purely for development and test purposes only and must be avoided for production installation of Xpanse.  ","version":"Next","tagName":"h3"},{"title":"Production Environments​","type":1,"pageTitle":"Database","url":"/xpanse/docs/database#production-environments","content":" We plan to support multiple RDBMS flavors. By support, we mean configurations for the database added and also all functionalities tested.  ","version":"Next","tagName":"h2"},{"title":"MySQL DB​","type":1,"pageTitle":"Database","url":"/xpanse/docs/database#mysql-db","content":" At the moment, this is the only DB that is fully supported. To use MySQL as the database for Xpanse, it must be activated by starting the application with profile mysql and by replacing the placeholders for databaseusername and password as below.  java -jar xpanse-runtime-1.0.0-SNAPSHOT.jar \\ -Dspring.profiles.active=mysql \\ -Dspring.datasource.username=${database-username} \\ -Dspring.datasource.password=${database-password}   Versions Supported​  Current supported version of MySQL is 8.1.0. This is the latest LTS release of MySQL.  Default Configuration​  The above command will start the Xpanse runtime with the following default configurations:  MySQL running on the same machine where Xpanse is running. (Same localhost)Database is listening on port 3306.Name of the database is xpanse. This must be created on the DB server. It will not be automatically created.  The Default configuration file can be found here.  Overriding Default Configuration​  We can override the above two default configurations by starting the application as below by replacing the placeholders with actual values.  java -jar xpanse-runtime-1.0.0-SNAPSHOT.jar \\ -Dspring.profiles.active=mysql \\ -Dspring.datasource.username=&lt;replace-with-db-username&gt; \\ -Dspring.datasource.password=&lt;replace-with-db-password&gt; \\ -D spring.datasource.url=jdbc:mysql://&lt;replace-with-db-hostname&gt;:&lt;replace-with-db-port&gt;/&lt;replace-with-db-name&gt;   Note: It is safe to provide the database-related properties as environment variables rather than passing them directly in the command line. In case of this, the same property name must be set in UPPERCASE and underscore separated instead of dot for all variables.  Note: Using this startup command, the database can run on any machine that is reachable from the Xpanse runtime application.  MySQL as a Docker Container​  MySQL offers official Docker images for running a database as a container. More details can be found here on the official page of MySQL website here and on DockerHub here.  Starting new container​  While starting the MySQL docker container for the first time, we can configure database-host, database-port anddatabase-name as below and the same can be used in starting the Xpanse runtime using the command described  above.  docker pull mysql:8.1.0   By starting the container with the below command, the database is started by automatically configuring the database with Xpanse database name, database user and password. In addition to that, password for the DB root user can also be updated to the value of our choice.  docker run --name ${container-name} \\ -e MYSQL_ROOT_PASSWORD=&lt;replace-with-db-root-password&gt; \\ -e MYSQL_DATABASE=&lt;replace-with-db-name&gt; \\ -e MYSQL_USER=&lt;replace-with-db-user&gt; \\ -e MYSQL_PASSWORD=&lt;replace-with-db-password&gt; \\ -p 3306:&lt;replace-with-db-port&gt; -d mysql:8.1.0   Note: To avoid passing database related properties in command line, we can use the --env-file option of the docker run command to store all sensitive data.  Database Objects Creation​  The application automatically creates all database objects such as tables needed by the application when it boots up and uses a database for the first time. ","version":"Next","tagName":"h3"},{"title":"Demo","type":0,"sectionRef":"#","url":"/xpanse/docs/FurtherReading/demos","content":"Demo The Eclipse Xpanse Demo shows you: how to register, update and delete a service.how to use the service catalog and order services.how to manage the ordered services - monitoring, migrating, etc.how to manage cloud provider credentialsand many more. The demo is available as video stream.","keywords":"","version":"Next"},{"title":"Developer Setup","type":0,"sectionRef":"#","url":"/xpanse/docs/developer-setup","content":"","keywords":"","version":"Next"},{"title":"Java Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#java-installation","content":" We need Java Developer Kit (JDK) version 21 installed. You can use openjdkor temurin for this.  ","version":"Next","tagName":"h2"},{"title":"Deployer Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#deployer-installation","content":" Depending on the type of deployers you intend to use, the below steps can be used to install necessary deployers for local development.  ","version":"Next","tagName":"h2"},{"title":"Terraform CLI Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#terraform-cli-installation","content":" Terraform CLI can be installed using the steps from the official guide.  ","version":"Next","tagName":"h3"},{"title":"OpenTofu CLI Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#opentofu-cli-installation","content":" Terraform CLI can be installed using the steps from the official guide.  ","version":"Next","tagName":"h3"},{"title":"Zitadel Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#zitadel-installation","content":" Install and configure Zitadel using steps mentioned the here.  ","version":"Next","tagName":"h2"},{"title":"NodeJS Installation​","type":1,"pageTitle":"Developer Setup","url":"/xpanse/docs/developer-setup#nodejs-installation","content":" NodeJS is necessary for UI development. It can be installed using the steps mentioned in the official guide. ","version":"Next","tagName":"h2"},{"title":"Resources","type":0,"sectionRef":"#","url":"/xpanse/docs/FurtherReading/resources","content":"Resources Pitch Slide DeckDemo Presentations at events EclipseCon 2022, Open Services Cloud: unleash cloud managed services (video)EclipseCon 2023 - Eclipse Xpanse - An Open Services Cloud Project (video)EclipseCon 2023 - Eclipse Xpanse - An Open Services Cloud Project (slides)EclipseCon 2023 - Open Cloud Services and an Open Cloud Computing Stack (video)EclipseCon 2023 - Open Cloud Services and an Open Cloud Computing Stack (slides)","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/xpanse/docs/intro","content":"","keywords":"","version":"Next"},{"title":"Getting Started​","type":1,"pageTitle":"Introduction","url":"/xpanse/docs/intro#getting-started","content":" Xpanse is composed by:  an orchestrator responsible for the managed services (deployment, start, stop, ...) and loading plugins specific for each supported cloud providerConfiguration Language for describing managed services and for deploying these managed services.a REST API to interact with the orchestratorruntime (including cloud provider plugins) assembling all components together in a running service ","version":"Next","tagName":"h2"},{"title":"Observability","type":0,"sectionRef":"#","url":"/xpanse/docs/observability","content":"","keywords":"","version":"Next"},{"title":"OpenTelemetry​","type":1,"pageTitle":"Observability","url":"/xpanse/docs/observability#opentelemetry","content":"   As a default implementation, we use OpenTelemetry to generate and collect telemetry data. The OpenTelemetry provided SDKs and auto-instrumentation features helps to generate all necessary data with no additional implementation. Using OpenTelemetry provides an advantage that, we generate data based on standards specified by OpenTelemetry and thereby gives us the flexibility to feed this data to any OpenTelemetry protocol supported backends.  ","version":"Next","tagName":"h3"},{"title":"Telemetry Data Generated​","type":1,"pageTitle":"Observability","url":"/xpanse/docs/observability#telemetry-data-generated","content":" Logs​  All application runtimes involved in the Xpanse stack, generates logs with useful information to trace a request end-to-end. Logs have metadata which provides very high level of traceability.  The OpenTelemetry auto-instrumentation SDK is then used to export all generated logs from existing logging frameworks to OTEL collector.  Metrics and Traces​  All application runtimes are provided with an option to enable OpenTelemetry's auto-instrumentation features which then generates metrics and traces.  ","version":"Next","tagName":"h3"},{"title":"Telemetry Data collector​","type":1,"pageTitle":"Observability","url":"/xpanse/docs/observability#telemetry-data-collector","content":" We can use any product which implements the OpenTelemetry specifications for collecting data. The collector's endpoint must then be configured in the data producing systems for forwarding the generated Telemetry data to the collector.  ","version":"Next","tagName":"h3"},{"title":"Components Generating Observability Data​","type":1,"pageTitle":"Observability","url":"/xpanse/docs/observability#components-generating-observability-data","content":" xpanse - activated using spring profile opentelemetryterraform-boot - activated using spring profile opentelemetrypolicy-man - activated by starting OpenTelemetry's instrumentation process together with policy-manzitadel - enabled by default  ","version":"Next","tagName":"h3"},{"title":"Sample Full Stack Observability​","type":1,"pageTitle":"Observability","url":"/xpanse/docs/observability#sample-full-stack-observability","content":" An example on how to enable auto-instrumentation for all Xpanse components and then export data to OTEL collector which can be later feed into Grafana monitoring stack can be found here. ","version":"Next","tagName":"h3"},{"title":"Policies","type":0,"sectionRef":"#","url":"/xpanse/docs/policies","content":"","keywords":"","version":"Next"},{"title":"OPA - Open Policy Agent​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#opa---open-policy-agent","content":"   Policies in OPA must be written in Rego which is a Policy Language designed by OPA project. More details on how policies can be written using Rego can be found here.  ","version":"Next","tagName":"h2"},{"title":"Example Use Cases​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#example-use-cases","content":" As an End user, we can use policies to validate if the managed service creates any resources or configuration in the end user's cloud infrastructure which may be not allowed by his/her organization.As a cloud service provider, we can use policies to validate if the service is being correctly deployed.As an integration test to validate if the service is deploying exactly what it is supposed to do.and many more.  ","version":"Next","tagName":"h2"},{"title":"End User Policies​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#end-user-policies","content":" End users can upload their OPA policies and these policies will be validated for all services ordered by the end user.  ","version":"Next","tagName":"h2"},{"title":"CSP Policies​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#csp-policies","content":" Cloud service providers can define policies for each of their service. These policies will be validated whenever the service is deployed.  ","version":"Next","tagName":"h2"},{"title":"Policy Management APIs​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#policy-management-apis","content":" Xpanse provides two sets of APIs for managing life-cycle of policies.  Services Policies Management - To add, update and delete service level policies by CSP.User Policies Management - To add, update and delete user level policies by end user.  ","version":"Next","tagName":"h2"},{"title":"Policy-Man​","type":1,"pageTitle":"Policies","url":"/xpanse/docs/policies#policy-man","content":" Xpanse uses an application called policy-man for the below purposes  Rego syntax validation when policies are uploaded.OPA policy validation when services are deployed. ","version":"Next","tagName":"h2"},{"title":"Plugins","type":0,"sectionRef":"#","url":"/xpanse/docs/plugins","content":"","keywords":"","version":"Next"},{"title":"Plugin Implementation​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#plugin-implementation","content":" A plugin is a class that implements the OrchestratorPlugininterface. The plugin implementation class must also be a Spring bean.  With the plugin implementation, the plugin will provide the cloud-specific implementation of handling credentials, reading monitoring data, handling infrastructure resources data provisioned via deployers, etc.  ","version":"Next","tagName":"h2"},{"title":"Plugin Activation​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#plugin-activation","content":" A plugin for a cloud provider is activated by default. But a plugin might need one or more mandatory configurations available for it to work. These mandatory configuration properties must be declared when the plugins are implemented. If any of the required configuration properties are not available, then such plugin is simply not considered for processing any requests.  Note: These mandatory variables will also be injected into the deployment environment as environment variables.  ","version":"Next","tagName":"h2"},{"title":"Openstack​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#openstack","content":" Mandatory configuration properties are the following  OS_AUTH_URL - Keystone URL of the Openstack installation.  Other optional config properties  OS_SERVICE_PROJECT - Openstack project to be used to get monitoring information. All metrics data is stored in a different central project. If this is not provided, then the project where the resource is hosted is used to get the metrics data.OS_PROXY_HOST and OS_PROXY_PORT - Proxy server information to reach the Openstack installation.OS_SSL_DISABLED - If set to true, the certificate validation on the REST API calls to Openstack installation will be disabled.  ","version":"Next","tagName":"h3"},{"title":"HuaweiCloud​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#huaweicloud","content":" No mandatory configuration properties required.  ","version":"Next","tagName":"h3"},{"title":"FlexibleEngine​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#flexibleengine","content":" No mandatory configuration properties required.  ","version":"Next","tagName":"h3"},{"title":"SCS - Sovereign Cloud Stack​","type":1,"pageTitle":"Plugins","url":"/xpanse/docs/plugins#scs---sovereign-cloud-stack","content":" No mandatory configuration properties required. But OS_AUTH_URL which is the keystone base URL of the SCS installation must be passed one of the fixed deployment variables as below in all the service registration requests.  name: OS_AUTH_URL description: SCS cloud instance to be used. kind: fix_env # this is important here. dataType: string mandatory: true sensitiveScope: none value: 'https://example.com'  ","version":"Next","tagName":"h3"},{"title":"Package Structure","type":0,"sectionRef":"#","url":"/xpanse/docs/package-structure","content":"","keywords":"","version":"Next"},{"title":"modules​","type":1,"pageTitle":"Package Structure","url":"/xpanse/docs/package-structure#modules","content":" This maven module is a parent module for most of the other maven modules within xpanse.  api​  Contains all the REST API controller classes and the exception handlers.  async​  Contains all classes related to async processing configuration for different use cases within Xpanse.  common​  Contains generic and utility classes which are used by multiple different modules.  credential​  contains all logic and caching for cloud provider credentials.  database​  contains all entities, DB queries and JPA related code.  deployment​  contains all code related to service deployment. All service deployers such terraform, opentofu, etc are also implemented in this module.  logging​  contains all code and config related to logging.  models​  contains all data models and exceptions that are exposed externally in our APIs. All data models here are automatically exported in the openapi doc.  Note:Ensure that this module does not have dependency to any other xpanse modules else it will result in cycle dependencies errors. This package must not contain any internal data classes.  monitor​  contains all code related to fetching and caching service metrics for deployed services.  observability​  contains all code related to observability and traceability of the xpanse stack.  Note: &gt; monitor module is for monitoring the customer's deployed clouds services whereas observability module is for monitoring the xpanse stack itself.  orchestrator​  This package is the central package for orchestrating service deployment, monitoring, cloud provider credentials, service state management. It also has all the internal data models used by Xpanse for all use-cases.  Policy​  This package contains all code related to OPA policy validation. Also, the policy-man REST client is part of this package.  security​  This package contains all code and config related to security within Xpanse. It contains the Oauth2 security of Xpanse APIs and also the encryption of sensitive order data.  servicetemplate​  contains all code for managing service templates.  workflow​  contains all code and config related to managing activiti workflow engine.  ","version":"Next","tagName":"h2"},{"title":"plugins​","type":1,"pageTitle":"Package Structure","url":"/xpanse/docs/package-structure#plugins","content":" contains all cloud provider specific integrations. Under plugins maven module, there is one submodule for each cloud provider supported by Xpanse.  ","version":"Next","tagName":"h2"},{"title":"runtime​","type":1,"pageTitle":"Package Structure","url":"/xpanse/docs/package-structure#runtime","content":" This is the package which contains the main spring boot class and also pulls all other maven modules listed above as dependencies to generate the final jar. ","version":"Next","tagName":"h2"},{"title":"Runtime","type":0,"sectionRef":"#","url":"/xpanse/docs/runtime","content":"","keywords":"","version":"Next"},{"title":"Pre-Requisites​","type":1,"pageTitle":"Runtime","url":"/xpanse/docs/runtime#pre-requisites","content":" If using local terraform module, the Xpanse Runtime host must have Terraform CLI installed. If using remote terraform-boot service, a remote Terrafom-boot service must be deployed/started.More details about the Terraform-boot project can be found here. Fully configured Zitadel instance.  ","version":"Next","tagName":"h2"},{"title":"Properties and Environment Variables​","type":1,"pageTitle":"Runtime","url":"/xpanse/docs/runtime#properties-and-environment-variables","content":" Xpanse has integration to multiple systems, and the aim is also to keep the system as flexible as possible and to cover all use-cases possible. Therefore, there are some configuration properties that the developer and the production administrators must take care of before starting/deploying xpanse.  Configuration properties of authentication layer. Documented here.Configuration properties of database layer. Documented here.Plugin activation variables. Documented here.  ","version":"Next","tagName":"h2"},{"title":"Local Development​","type":1,"pageTitle":"Runtime","url":"/xpanse/docs/runtime#local-development","content":" Clone and Build​  Clone the project using the command below  $ git clone https://github.com/eclipse-xpanse/xpanse $ cd xpanse   Then compile the entire project using the below command  $ ./mvnw clean install -DskipTests   Run​  Ensure all properties mentioned in the above section are correctly set.  From Command Line​  If you have a fully configured Zitadel instance running on your local system, then you can use the below command to start the application by passing all variables.  To start the application from the command line, run the below application from the root of the project.  $ java -jar runtime/target/xpanse-runtime-1.0.0-SNAPSHOT.jar \\ --authorization-api-client-id=${client-id} \\ --authorization-api-client-secret=${client-secret} \\ --authorization-swagger-ui-client-id=${swagger-ui-cleint-id}   If you would like to use our zitadel-testbed, then start the server using the below command. This will automatically set properties required for connecting to our Zitadel test bed.  $ cd runtime/target $ java -jar xpanse-runtime-1.0.0-SNAPSHOT.jar --spring.profiles.active=zitadel,zitadel-testbed   By default, Xpanse Runtime starts using Terraform-boot. If you want to use local terraform, just don't activate the terraform-boot scenario in the application.properties configuration file.  spring.profiles.active=zitadel,zitadel-testbed   From IDE​  Or the application can be started using the IDE by executing the main application directly. Below is the example from IntellijIdea    You must see the below messages in the console.   _ __ ____ ____ _ ____ _____ ___ | |/_/ / __ \\ / __ `/ / __ \\ / ___/ / _ \\ _&gt; &lt; / /_/ / / /_/ / / / / / (__ ) / __/ /_/|_| / .___/ \\__,_/ /_/ /_/ /____/ \\___/ /_/ xpanse 1.0.0-SNAPSHOT (2023) 13:44:19.633 [main] INFO o.e.xpanse.runtime.XpanseApplication - Starting XpanseApplication using Java 17.0.5 with PID 7344 13:44:19.645 [main] INFO o.e.xpanse.runtime.XpanseApplication - No active profile set, falling back to 1 default profile: &quot;default&quot; 13:44:22.211 [main] INFO o.e.x.o.FileOrchestratorStorage - No other storage beans found. Using default file storage. 13:44:23.878 [main] WARN o.e.x.o.OrchestratorService - No xpanse plugins loaded by the runtime. 13:44:23.886 [main] INFO o.e.xpanse.runtime.XpanseApplication - Started XpanseApplication in 5.029 seconds (process running for 5.992)   You can check the status of the runtime by opening the swagger UI from any browser:  http://localhost:8080/swagger-ui/index.html   ","version":"Next","tagName":"h3"},{"title":"Production​","type":1,"pageTitle":"Runtime","url":"/xpanse/docs/runtime#production","content":" Ensure all properties mentioned in the above section are correctly set.  Run using jar​  Download the released runtime jar from GitHub releases. You can get the latest from here.  After downloading, follow the same steps mentioned in this section.  Run using Docker image​  You can start the runtime using our released docker image, and this is the preferred way. This image contains all necessary tools preinstalled.  $ docker pull ghcr.io/eclipse-xpanse/xpanse:${release-version} $ docker run -d -p 8080:8080 --name xpanse -e &quot;SPRING_PROFILES_ACTIVE=zitadel,mariadb&quot; ghcr.io/eclipse-xpanse/xpanse:${release-version} $ docker logs xpanse   Note: It is safe to provide all properties as environment variables rather than passing them directly in the command line. In case of this, the same property name must be set in UPPERCASE for all 4 variables. For running, using docker image, we can use the --env-file option of the docker run command to store all sensitive data. Again here the property names must be in UPPERCASE.  Running API behind a proxy​  For running the runtime application behind a proxy, we must ensure that the proxy forwards the correct X-Forwarded-*headers to the API. This is necessary as the API has some features where the links to html pages are returned and this link will have the correct protocol and host only when these headers are set.  In the case of Nginx, the configuration will look like this  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_set_header Host $host;  ","version":"Next","tagName":"h3"},{"title":"Service Hosting Types","type":0,"sectionRef":"#","url":"/xpanse/docs/service-hosting","content":"","keywords":"","version":"Next"},{"title":"Available Service Hosting Types​","type":1,"pageTitle":"Service Hosting Types","url":"/xpanse/docs/service-hosting#available-service-hosting-types","content":" ","version":"Next","tagName":"h2"},{"title":"Self-Hosted​","type":1,"pageTitle":"Service Hosting Types","url":"/xpanse/docs/service-hosting#self-hosted","content":" In this case, the service is deployed on the end customer's cloud account. When a service is self-hosted, the end user can view more information such as service deployment errors, etc. The service vendor only can view only very basic details of the deployed service. The service vendor must contact the end user in case any information is required.  ","version":"Next","tagName":"h3"},{"title":"Service-Vendor-Hosted​","type":1,"pageTitle":"Service Hosting Types","url":"/xpanse/docs/service-hosting#service-vendor-hosted","content":" In this case, the service is deployed on the service vendor's cloud account. When a service is service-vendor hosted, the end user has very restricted access to the deployed service details. The user will only receive the end point details to access the service.  The service vendor has more access to the service deployment details. But the service vendor cannot access the end point details.  This mode makes more sense to host a SaaS type of managed service.  ","version":"Next","tagName":"h3"},{"title":"Credentials​","type":1,"pageTitle":"Service Hosting Types","url":"/xpanse/docs/service-hosting#credentials","content":" Service vendors can use the ISV Cloud Credentials Management services to manage the cloud accounts for service deployments.  End users can use the User Cloud Credentials Management services to manage the cloud accounts for service deployments.  ","version":"Next","tagName":"h2"},{"title":"Service With Multiple Service Hosting Types​","type":1,"pageTitle":"Service Hosting Types","url":"/xpanse/docs/service-hosting#service-with-multiple-service-hosting-types","content":" The service vendor must specify the service hosting type in the service template. One service template can only offer a service on only one hosting type. So when the service vendor want to offer service on multiple hosting types, then one service template must be registered for each hosting type. ","version":"Next","tagName":"h2"},{"title":"Supported Clouds","type":0,"sectionRef":"#","url":"/xpanse/docs/supported-clouds","content":"Supported Clouds Xpanse will be available on several cloud providers &quot;out of the box&quot;. Here's the list of the cloud providers supporting OSC: Huawei CloudOpenstack powered cloudFlexibleEngineSovereign Cloud Stack (SCS)","keywords":"","version":"Next"},{"title":"Service Deployment","type":0,"sectionRef":"#","url":"/xpanse/docs/service-deployment","content":"","keywords":"","version":"Next"},{"title":"Deployer Implementation​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#deployer-implementation","content":" Every deployer must implement the methods defined in the Deployer interface. The deployer implementation will abstract all the service deployment tasks that must be executed for provisioning the service and return the result as DeployResult object.  ","version":"Next","tagName":"h2"},{"title":"Processing Deployment Results​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#processing-deployment-results","content":" Each deployer can put all the necessary information about deployment results to a privateProperties map in DeployResult object.  Resource Handlers​  Each plugin must implement a DeployResourceHandler for each DeployerKind and this will be invoked to extract the cloud resources deployed from the DeployerResult.    ","version":"Next","tagName":"h3"},{"title":"Asynchronous Processing​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#asynchronous-processing","content":" Since a service deployment can take longer depending on the complexity of the service and the resources required for it, the entire deployment process is implemented to run asynchronously.  After the deploy or the destroy request is submitted, the runtime validates the request and the client receives an accepted/rejected message synchronously. After this, the runtime hands over the deployment request to another thread which executes the deployment independently.  The clients can then fetch the status of the deployment using getDeployedServiceDetailsById service.  ","version":"Next","tagName":"h2"},{"title":"Terraform​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#terraform","content":" Terraform script that must be executed must be passed as is, in the service definition when the service is registered. You can find examples of how the script can look like in the samples folder.  Terraform binaries must be installed on the system where runtime is running. Or use our docker image, which contains all required software installed.  ","version":"Next","tagName":"h2"},{"title":"Terraform Boot​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#terraform-boot","content":" To offload the service deployment tasks from the Xpanse's main runtime engine, we created a project called terraform-boot. We used this application for all our Terraform related tasks.  ","version":"Next","tagName":"h3"},{"title":"Script Validation​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#script-validation","content":" As part of the service registration process, Xpanse validates the syntax of the Terraform script provided. The service is registered only when the script validation is successful.  We use the Terraform validate feature to achieve this.  ","version":"Next","tagName":"h3"},{"title":"Script Execution​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#script-execution","content":" When the customer orders the service, the following happens  Generate a unique ID for the service requested. This is based on UUID.Create a folder with this ID as the name.From the runtime, call the start the Terraform process outside the JVM to do the following  Inside the folder, the runtime will then create a Terraform workspace.Execute the Terraform scripts  Note: To avoid dependency on the filesystem, the state terraform.tfstate file contents are copied to the database at the end of the service deployment. We reuse this later when the customer requests to destroy the service.  ","version":"Next","tagName":"h3"},{"title":"Reading Script Output​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#reading-script-output","content":" After the runtime starts the Terraform script as a system command, it then starts to listen to stdout and stderr of the job to gather all output generated from the script.  ","version":"Next","tagName":"h3"},{"title":"Capturing Service Details​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#capturing-service-details","content":" For any service ordered by the customer, it is important to return the details of the ordered service. Such as the IPs, credentials, etc. which the customer must use to start consuming the service.  We use the Terraform output feature to get such information from the service deployment. So it is important to add the output section to the scripts. The same is also used by the Xpanse UI for displaying the service details.  ","version":"Next","tagName":"h3"},{"title":"Version Configuration For Terraform Providers​","type":1,"pageTitle":"Service Deployment","url":"/xpanse/docs/service-deployment#version-configuration-for-terraform-providers","content":" Xpanse currently uses Terraform to orchestrate resources on cloud providers, but versions of Terraform for cloud providers are in constant iteration. In order to configure the Terraform version of the cloud providers more conveniently and quickly, you can configure the Terraform version of the cloud providers in the xpanse configuration file.  The Version Key Of The Terraform Providers​  Terraform Providers\tkeyAWS\tterraform.provider.aws.version HuaweiCloud\tterraform.provider.huaweicloud.version OpenStack\tterraform.provider.openstack.version FlexibleEngine\tterraform.provider.flexibleengine.version  How To Configure The Version of Terraform Providers​  For how to configure the version value of Terraform Providers, please refer to the chapter ofVersion Constraints in https://developer.hashicorp.com/terraform/language/providers/requirements#version-constraints  The following are some examples, please refer to  terraform.provider.aws.version=~&gt; 4.0 terraform.provider.openstack.version=&gt;= 1.48.0 terraform.provider.flexibleengine.version=&gt;= 1.30.0 terraform.provider.huaweicloud.version=~&gt; 1.51.0  ","version":"Next","tagName":"h3"},{"title":"UI","type":0,"sectionRef":"#","url":"/xpanse/docs/ui","content":"","keywords":"","version":"Next"},{"title":"Development Setup​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#development-setup","content":" Project is built using ReactJS library. As we use TypeScript here, we must ensure all objects have its type explicit defined.  GUI components are built using antd library.  Authentication and authorization are built using Zitadel which is an oauth2 provider.  ","version":"Next","tagName":"h2"},{"title":"Zitadel Configuration​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#zitadel-configuration","content":" Before we can start using the UI, we must ensure Zitadel instance that we consider using, has all the required configuration. Details can be found here.  ","version":"Next","tagName":"h2"},{"title":"Configuration Properties​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#configuration-properties","content":" All required configuration parameters must be added to .env file here. Even if we do not have a valid default value, we must just add empty value. This file serves as a reference to all required properties.  Very Important: Since React is compiled to a static app, all configuration values can be seen directly in the browser too. Therefore, no secure configurations such as passwords, keys, etc. must be added here.  ","version":"Next","tagName":"h2"},{"title":"Oauth Configuration​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#oauth-configuration","content":" For local environments, the access_tokens are stored with in the browser storage. This is not safe, but it is enough for non-production environments and for debugging purposes.  For production environments, we must use Service Workers which will block anyone to access the token. This can be enabled by making the following configurations.  REACT_APP_AUTH_USE_SERVICE_WORKER_ONLY=true   and the file OidcTrustedDomains.js must be updated with correct information.oidcDomains must have the identity provider URL and accessTokenDomains must have the Xpanse backend server URL.  Note: if the same must be used with our official docker images, then this file need not be touched. It will be automatically set from the environment variables.  ","version":"Next","tagName":"h2"},{"title":"Setting Configuration Values​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#setting-configuration-values","content":" .env Files​  Set values in the .env files. All default values are set in .env files. These are automatically loaded by React and there is no need to do anything for this to be loaded.For non-default properties or to override the values is .env, we can set the values in new .env files and load them using env-cmd framework which will automatically inject the variables. Example can be found here  Important: .env files must be used only for default configurations or for dev configurations values.  Environment Variables​  All variables can be overridden by setting environment variables and then running the npm run start for development or with docker run for production.  ","version":"Next","tagName":"h3"},{"title":"Getting Configuration Values​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#getting-configuration-values","content":" We have a custom implementation which reads the configuration from all sources and provides a unified configuration map. Only this must be used for reading configuration from the React app.  Implementation can be found here.  ","version":"Next","tagName":"h3"},{"title":"Starting local development server​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#starting-local-development-server","content":" In the project directory, you can run the below command to start the local development server. This also additionally needs nodejs to be installed on the development machine.  If there is a local development Zitadel instance and backend API instance, then we must set REACT_APP_ZITADEL_CLIENT_ID and REACT_APP_XPANSE_API_URL environment variables with respective values and then run the below command for the application to start.  $ npm run start   If you wish to use our central Zitadel testbed instance, then simply start the application with the below command.  $ npm run start-with-zitadel-testbed   Open http://localhost:3000 to view it in the browser.  ","version":"Next","tagName":"h2"},{"title":"Static Code Analysis​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#static-code-analysis","content":" We use eslint and knip to statically analyze code. Always run the below command locally to ensure the changes made results in no errors. This will also validate the code format. In case of any errors, the CI pipeline will fail when a PR is opened.   npx eslint . --ext .js,.jsx,.ts,.tsx --config package.json --max-warnings=0 npx knip   ","version":"Next","tagName":"h3"},{"title":"Code Formatting​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#code-formatting","content":" We use prettier to format our UI code. To auto format the code, you can run the below command.  npx prettier --config .prettierrc --write .   ","version":"Next","tagName":"h3"},{"title":"Generate Rest Client for Xpanse API​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#generate-rest-client-for-xpanse-api","content":" We use the openapi generator to generate data models and rest client from the openapi json file. The following steps must be followed to generate a new client and data models whenever there is a new version if the swagger json.  Copy the openapi file to OpenApi JSON FileRun the code generator as below cd src/xpanse-api npx openapi-typescript-codegen --input api.json --output ./generated --exportSchemas false This step will generate all required models and clientAdd license headers.Format newly generated files.  ","version":"Next","tagName":"h3"},{"title":"Build for production​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#build-for-production","content":" The only recommended way to run UI in production is to use the docker image  ","version":"Next","tagName":"h2"},{"title":"Docker Image​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#docker-image","content":" Docker image for the UI project is based on nginx base image. This is because the project only serves static content.  As part of our UI release process, we deliver our official images to GitHub packages. All available images can be found here.  ","version":"Next","tagName":"h2"},{"title":"Run UI Container​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#run-ui-container","content":" Container runs the application on port 3000 by default and exposes the UI using HTTP. We must use another SSL load balancer to expose the UI for end users.  Production configuration values must be passed as environment variables to docker run for the below vars using -e option.  REACT_APP_ZITADEL_AUTHORITY_NAME # URL for the Oauth provider REACT_APP_ZITADEL_CLIENT_ID # Client ID provided by the Oauth provider for UI REACT_APP_XPANSE_API_URL # Backend API URL REACT_APP_AUTH_USE_SERVICE_WORKER_ONLY=true # for production. Otherwise, this step config can be ignored.   docker pull ghcr.io/eclipse-xpanse/xpanse-ui:${version} docker run -d --name ui xpanse-ui   ","version":"Next","tagName":"h3"},{"title":"Application Logs​","type":1,"pageTitle":"UI","url":"/xpanse/docs/ui#application-logs","content":" All logs from nginx are routed to stdout by default. Using the below command, all application logs can be viewed.  docker logs ui  ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}